{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "084e0c05-6d24-43e0-9e3f-2543c11e2a87",
   "metadata": {},
   "source": [
    "# Manuscript Companion for: \"Mapping Hippocampal and Thalamic Atrophy in Epilepsy: A 7T MRI Study\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e086cb6-6df3-4cf3-93f5-8fcfa35209f8",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d2b384b-5b9f-4986-9e79-886b9cc10317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(r'subfield_volumes_by_pt.pickle', \"rb\") as input_file:\n",
    "    e = pickle.load(input_file)\n",
    "    seg_vol = e['seg_vol']\n",
    "    vol_pts = e['vol_pts']\n",
    "    fmri_lab= e['vol_lab']\n",
    "\n",
    "pt_info = pd.read_excel('/Users/smouc/LittLab/Alfredo/Segmentation/Code/hippo_thal_7t_metadata_updated_5SENSE.xlsx').sort_values(by='Subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ccc63c8e-4301-4551-beda-25312b14a4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n",
      "(55, 24)\n"
     ]
    }
   ],
   "source": [
    "group_assignments = np.array(list(map(lambda x: int(pt_info[pt_info['Subject']==x]['Lat'].values[0] == 'Control'), vol_pts)))\n",
    "protocol_versions = np.array(list(map(lambda x: pt_info[pt_info['Subject']==x]['version'].values[0], vol_pts)))\n",
    "\n",
    "from neuroCombat import neuroCombat\n",
    "\n",
    "# Specifying the batch (scanner variable) as well as a biological covariate to preserve:\n",
    "covars = {'batch':protocol_versions,\n",
    "          'group':group_assignments} \n",
    "covars = pd.DataFrame(covars)\n",
    "\n",
    "# To specify names of the variables that are categorical:\n",
    "categorical_cols = ['group']\n",
    "\n",
    "# To specify the name of the variable that encodes for the scanner/batch covariate:\n",
    "batch_col = 'batch'\n",
    "\n",
    "#Harmonization step:\n",
    "data_combat = neuroCombat(dat=seg_vol, # should be (samples, features)\n",
    "    covars=covars,\n",
    "    batch_col=batch_col,\n",
    "    categorical_cols=categorical_cols)[\"data\"]\n",
    "\n",
    "seg_vol = data_combat.T\n",
    "print(seg_vol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e351b914-ae2a-4b31-8b6c-4e47add0bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_vol_pts = [x for x in vol_pts if (pt_info[pt_info['Subject']==x]['Final_Loc'].values[0] != 'Control')]\n",
    "\n",
    "temporal = np.array(list(map(lambda x: pt_info[pt_info['Subject']==x]['Final_Loc'].values[0] == 'Temporal', ep_vol_pts)))\n",
    "frontal = np.array(list(map(lambda x: pt_info[pt_info['Subject']==x]['Final_Loc'].values[0] == 'Frontal', ep_vol_pts)))\n",
    "control = np.array(list(map(lambda x: pt_info[pt_info['Subject']==x]['Final_Loc'].values[0] == 'Control', ep_vol_pts)))\n",
    "left = np.array(list(map(lambda x: pt_info[pt_info['Subject']==x]['Lat'].values[0] == 'L', ep_vol_pts)))\n",
    "right = np.array(list(map(lambda x: pt_info[pt_info['Subject']==x]['Lat'].values[0] == 'R', ep_vol_pts)))\n",
    "bilateral = np.array(list(map(lambda x: pt_info[pt_info['Subject']==x]['Lat'].values[0] == 'B', ep_vol_pts)))\n",
    "lesional = np.array(list(map(lambda x: pt_info[pt_info['Subject']==x]['MRI_Lesional'].values[0] == 'Lesional', ep_vol_pts)))\n",
    "nonlesional = np.array(list(map(lambda x: pt_info[pt_info['Subject']==x]['MRI_Lesional'].values[0] == 'Nonlesional', ep_vol_pts)))\n",
    "mts = np.array(list(map(lambda x: pt_info[pt_info['Subject']==x]['MTS (y/n)'].values[0] == 'y', ep_vol_pts)))\n",
    "nonmts = np.array(list(map(lambda x: pt_info[pt_info['Subject']==x]['MTS (y/n)'].values[0] == 'n', ep_vol_pts)))\n",
    "\n",
    "seg_vol_ep = seg_vol[[pt_info[pt_info['Subject']==x]['Final_Loc'].values[0] != 'Control' for x in vol_pts], :]\n",
    "seg_vol_hc = seg_vol[[pt_info[pt_info['Subject']==x]['Final_Loc'].values[0] == 'Control' for x in vol_pts], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68ad8b3-b01e-48d3-98b3-bb98c5afccef",
   "metadata": {},
   "source": [
    "# Build LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3226e5c7-8dec-488d-b9a9-a6fbe4eacc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gen_save_lda(seg_vol, groups, save_name):\n",
    "# groups = np.array(list(map(lambda x: int(pt_info[pt_info['Subject']==x]['Lat'].values[0] == 'Control'), vol_pts)))\n",
    "\n",
    "# seg_vol = patients x structures\n",
    "# ep seg_vol = seg_vol[group_assignments == 0, :]; control seg_vol = seg_vol[group_assignments == 1, :]\n",
    "\n",
    "    k=4\n",
    "    numrun = 10\n",
    "    numi = 100\n",
    "    dup = 0\n",
    "\n",
    "    ep_seg_vol = seg_vol[groups == 0, :] # epilepsy\n",
    "    c_seg_vol = seg_vol[groups == 1, :] # control\n",
    "\n",
    "    # z-score and convert to LDA compatible dataset\n",
    "    ep_seg_vol_norm = np.abs((ep_seg_vol - np.mean(c_seg_vol,axis=0))/np.std(c_seg_vol,axis=0)*10).astype(int)\n",
    "\n",
    "    seg_vol_norm_left = ep_seg_vol_norm[left,:]\n",
    "    seg_vol_norm_right = ep_seg_vol_norm[right,:]\n",
    "\n",
    "    ind = np.hstack([np.arange(4, 8), np.arange(0, 4), np.arange(16, 24), np.arange(8, 16)])\n",
    "    seg_vol_norm_right_flipped = seg_vol_norm_right[:, ind]\n",
    "\n",
    "    ep_seg_vol_norm_all = np.vstack([seg_vol_norm_left, seg_vol_norm_right_flipped])\n",
    "    \n",
    "    best_of_best_model = []\n",
    "    best_of_best_comp = []\n",
    "\n",
    "    for run in range(numrun):\n",
    "        out_components = []\n",
    "        out_models = []\n",
    "\n",
    "        # generate 100 models\n",
    "        i=0\n",
    "        while i <= numi:\n",
    "            lda = LatentDirichletAllocation(n_components=k)\n",
    "            lda.fit(ep_seg_vol_norm)\n",
    "\n",
    "            if (np.min(np.std(lda.components_ / np.tile(np.sum(lda.components_, axis=1), (24,1)).T, axis=1)) >= 10**-4):\n",
    "                out_components.append(lda.components_)\n",
    "                out_models.append(lda)\n",
    "                i+=1\n",
    "            else:\n",
    "                dup+=1\n",
    "\n",
    "        comp_corr = np.zeros((len(out_models),len(out_models)))\n",
    "\n",
    "        # iterate through every pair of models and find the largest correlation between any pair of factors\n",
    "        for i in range(len(out_models)):\n",
    "            for j in range(i+1, len(out_models)):\n",
    "                i_comp = out_components[i]/out_components[i].sum(axis=1)[:, np.newaxis]\n",
    "                j_comp = out_components[j]/out_components[j].sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "                p_all = []\n",
    "                for f1 in range(k):\n",
    "                    for f2 in range(k):\n",
    "                        p_all.append(stats.pearsonr(i_comp[f1,:], j_comp[f2,:]))\n",
    "\n",
    "                comp_corr[i,j] = np.max(p_all)\n",
    "\n",
    "        comp_corr += comp_corr.T\n",
    "        comp_corr += np.eye(len(out_models))\n",
    "\n",
    "        avg_corr = np.mean(comp_corr, axis=1)\n",
    "        best_run = np.argmax(avg_corr)\n",
    "\n",
    "        best_of_best_model.append(out_models[best_run])\n",
    "        best_of_best_comp.append(out_components[best_run])\n",
    "\n",
    "    best_comp_corr = np.zeros((numrun,numrun))\n",
    "\n",
    "    for i in range(numrun):\n",
    "        for j in range(i+1, numrun):\n",
    "            i_comp = best_of_best_comp[i]/best_of_best_comp[i].sum(axis=1)[:, np.newaxis]\n",
    "            j_comp = best_of_best_comp[j]/best_of_best_comp[j].sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "            p_all = []\n",
    "            for f1 in range(k):\n",
    "                for f2 in range(k):\n",
    "                    p_all.append(stats.pearsonr(i_comp[f1,:], j_comp[f2,:]))\n",
    "\n",
    "            best_comp_corr[i,j] = np.max(p_all)\n",
    "\n",
    "    best_comp_corr += best_comp_corr.T\n",
    "    best_comp_corr += np.eye(numrun)\n",
    "\n",
    "    avg_corr = np.mean(best_comp_corr, axis=1)\n",
    "    best_run = np.argmax(avg_corr)\n",
    "    lda_components_new = best_of_best_comp[best_run]/best_of_best_comp[best_run].sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    finalout_factors = best_of_best_model[best_run].transform(ep_seg_vol_norm_all)\n",
    "\n",
    "    with open(save_name, 'wb') as output_file:\n",
    "        pickle.dump({'lda_components':lda_components_new, 'lda_model':best_of_best_model[best_run], 'pt_factors':finalout_factors}, output_file)\n",
    "\n",
    "    print(dup)\n",
    "    return(finalout_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8725c3-23e4-4c34-84f6-6b1b4ae88fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = np.array(list(map(lambda x: int(pt_info[pt_info['Subject']==x]['Lat'].values[0] == 'Control'), vol_pts)))\n",
    "out = gen_save_lda(seg_vol, groups, 'lda_components.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab3f00b-dec4-4f6a-9333-deabdb00fec9",
   "metadata": {},
   "source": [
    "## Figure 2 - Comparison of Hippocampal and Thalamic volumes in epilepsy subgroups vs controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ea9b8c-78e0-463b-b3de-b05bcf019152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "pv.global_theme.cmap = 'RdBu'\n",
    "\n",
    "def plot_ashs_no_tail(vals, vmin, vmax):\n",
    "    # Load the Left Hippocampus\n",
    "    l_ca1 = pv.read('../../../source_data/surfaces/hippocampus/hippocampus00001.stl')\n",
    "    l_ca2 = pv.read('../../../source_data/surfaces/hippocampus/hippocampus00002.stl')\n",
    "    l_dg = pv.read('../../../source_data/surfaces/hippocampus/hippocampus00003.stl')\n",
    "    l_ca3 = pv.read('../../../source_data/surfaces/hippocampus/hippocampus00004.stl')\n",
    "\n",
    "    l_ca1.point_data['Segmentation'] = vals[0]\n",
    "    l_ca2.point_data['Segmentation'] = vals[1]\n",
    "    l_dg.point_data['Segmentation'] = vals[2]\n",
    "    l_ca3.point_data['Segmentation'] = vals[3]\n",
    "\n",
    "    hippocampus = l_ca1.merge([l_ca1, l_ca2, l_dg, l_ca3])\n",
    "\n",
    "\n",
    "    # Load the Right Hippocampus\n",
    "    r_ca1 = pv.read('../../../source_data/surfaces/hippocampus/hippocampus00101.stl')\n",
    "    r_ca2 = pv.read('../../../source_data/surfaces/hippocampus/hippocampus00102.stl')\n",
    "    r_dg = pv.read('../../../source_data/surfaces/hippocampus/hippocampus00103.stl')\n",
    "    r_ca3 = pv.read('../../../source_data/surfaces/hippocampus/hippocampus00104.stl')\n",
    "\n",
    "    r_ca1.point_data['Segmentation'] = vals[4]\n",
    "    r_ca2.point_data['Segmentation'] = vals[5]\n",
    "    r_dg.point_data['Segmentation'] = vals[6]\n",
    "    r_ca3.point_data['Segmentation'] = vals[7]\n",
    "\n",
    "    hippocampus = hippocampus.merge([r_ca1, r_ca2, r_dg, r_ca3])\n",
    "\n",
    "    # Do the actual plotting\n",
    "    # Hippocampus Camera Position\n",
    "    hipp_cpos = [(-9.979561975549055, 10.84928567303749, 123.90691105330777), (-0.04879951477050781, 14.638345837593079, -15.511809825897217), (0.06734247854283312, 0.9972198643766981, 0.03189878800563263)]\n",
    "\n",
    "\n",
    "    p = pv.Plotter()\n",
    "    p.add_mesh(hippocampus)\n",
    "    p.update_scalar_bar_range([vmin, vmax])\n",
    "\n",
    "    p.show(jupyter_backend='static', cpos=hipp_cpos)\n",
    "\n",
    "def plot_ashs_no_ca23(vals, vmin, vmax):\n",
    "    # Load the Left Hippocampus\n",
    "    l_ca1 = pv.read('/Users/allucas/Documents/research/CNT/P36_hippo_thal_7t/source_data/surfaces/hippocampus/hippocampus00001.stl')\n",
    "    l_ca2 = pv.read('/Users/allucas/Documents/research/CNT/P36_hippo_thal_7t/source_data/surfaces/hippocampus/hippocampus00002.stl')\n",
    "    l_dg = pv.read('/Users/allucas/Documents/research/CNT/P36_hippo_thal_7t/source_data/surfaces/hippocampus/hippocampus00003.stl')\n",
    "    l_ca3 = pv.read('/Users/allucas/Documents/research/CNT/P36_hippo_thal_7t/source_data/surfaces/hippocampus/hippocampus00004.stl')\n",
    "    l_tail = pv.read('/Users/allucas/Documents/research/CNT/P36_hippo_thal_7t/source_data/surfaces/hippocampus/hippocampus00005.stl')\n",
    "\n",
    "    l_ca1.point_data['Segmentation'] = vals[0]\n",
    "    \n",
    "    l_dg.point_data['Segmentation'] = vals[2]\n",
    "\n",
    "    l_tail.point_data['Segmentation'] = vals[4]\n",
    "\n",
    "    hippocampus = l_ca1.merge([l_ca1, l_dg, l_tail])\n",
    "\n",
    "\n",
    "    # Load the Right Hippocampus\n",
    "    r_ca1 = pv.read('/Users/allucas/Documents/research/CNT/P36_hippo_thal_7t/source_data/surfaces/hippocampus/hippocampus00101.stl')\n",
    "    r_ca2 = pv.read('/Users/allucas/Documents/research/CNT/P36_hippo_thal_7t/source_data/surfaces/hippocampus/hippocampus00102.stl')\n",
    "    r_dg = pv.read('/Users/allucas/Documents/research/CNT/P36_hippo_thal_7t/source_data/surfaces/hippocampus/hippocampus00103.stl')\n",
    "    r_ca3 = pv.read('/Users/allucas/Documents/research/CNT/P36_hippo_thal_7t/source_data/surfaces/hippocampus/hippocampus00104.stl')\n",
    "    r_tail = pv.read('/Users/allucas/Documents/research/CNT/P36_hippo_thal_7t/source_data/surfaces/hippocampus/hippocampus00105.stl')\n",
    "\n",
    "    r_ca1.point_data['Segmentation'] = vals[5]\n",
    "    r_dg.point_data['Segmentation'] = vals[7]\n",
    "    r_tail.point_data['Segmentation'] = vals[9]\n",
    "\n",
    "    hippocampus = hippocampus.merge([r_ca1, r_dg, r_tail])\n",
    "\n",
    "    # Do the actual plotting\n",
    "    # Hippocampus Camera Position\n",
    "    hipp_cpos = [(-9.979561975549055, 10.84928567303749, 123.90691105330777), (-0.04879951477050781, 14.638345837593079, -15.511809825897217), (0.06734247854283312, 0.9972198643766981, 0.03189878800563263)]\n",
    "\n",
    "\n",
    "    p = pv.Plotter()\n",
    "    p.add_mesh(hippocampus)\n",
    "    p.update_scalar_bar_range([vmin, vmax])\n",
    "\n",
    "    p.show(jupyter_backend='static', cpos=hipp_cpos)\n",
    "\n",
    "def plot_thomas(vals, vmin, vmax):\n",
    "    # Load the Left Thalamus\n",
    "    l_av = pv.read('../../../source_data/surfaces/thalamus/thalamus00002.stl')\n",
    "    l_va = pv.read('../../../source_data/surfaces/thalamus/thalamus00004.stl')\n",
    "    l_vla = pv.read('../../../source_data/surfaces/thalamus/thalamus00005.stl')\n",
    "    l_vlp = pv.read('../../../source_data/surfaces/thalamus/thalamus00006.stl')\n",
    "    l_vpl = pv.read('../../../source_data/surfaces/thalamus/thalamus00007.stl')\n",
    "    l_pul = pv.read('../../../source_data/surfaces/thalamus/thalamus00008.stl')\n",
    "    l_cm = pv.read('../../../source_data/surfaces/thalamus/thalamus00011.stl')\n",
    "    l_md = pv.read('../../../source_data/surfaces/thalamus/thalamus00012.stl')\n",
    "\n",
    "\n",
    "    l_av.point_data['Segmentation'] = vals[0]\n",
    "    l_va.point_data['Segmentation'] = vals[1]\n",
    "    l_vla.point_data['Segmentation'] = vals[2]\n",
    "    l_vlp.point_data['Segmentation'] = vals[3]\n",
    "    l_vpl.point_data['Segmentation'] = vals[4]\n",
    "    l_pul.point_data['Segmentation'] = vals[5]\n",
    "    l_cm.point_data['Segmentation'] = vals[6]\n",
    "    l_md.point_data['Segmentation'] = vals[7]\n",
    "\n",
    "    thalamus_l = l_av.merge([l_va, l_vla, l_vlp, l_vpl, l_pul, l_cm, l_md])\n",
    "\n",
    "\n",
    "    # Load the Right Thalamus\n",
    "    r_av = pv.read('../../../source_data/surfaces/thalamus/thalamus00102.stl')\n",
    "    r_va = pv.read('../../../source_data/surfaces/thalamus/thalamus00104.stl')\n",
    "    r_vla = pv.read('../../../source_data/surfaces/thalamus/thalamus00105.stl')\n",
    "    r_vlp = pv.read('../../../source_data/surfaces/thalamus/thalamus00106.stl')\n",
    "    r_vpl = pv.read('../../../source_data/surfaces/thalamus/thalamus00107.stl')\n",
    "    r_pul = pv.read('../../../source_data/surfaces/thalamus/thalamus00108.stl')\n",
    "    r_cm = pv.read('../../../source_data/surfaces/thalamus/thalamus00111.stl')\n",
    "    r_md = pv.read('../../../source_data/surfaces/thalamus/thalamus00112.stl')\n",
    "\n",
    "\n",
    "    r_av.point_data['Segmentation'] = vals[8]\n",
    "    r_va.point_data['Segmentation'] = vals[9]\n",
    "    r_vla.point_data['Segmentation'] = vals[10]\n",
    "    r_vlp.point_data['Segmentation'] = vals[11]\n",
    "    r_vpl.point_data['Segmentation'] = vals[12]\n",
    "    r_pul.point_data['Segmentation'] = vals[13]\n",
    "    r_cm.point_data['Segmentation'] = vals[14]\n",
    "    r_md.point_data['Segmentation'] = vals[15]\n",
    "\n",
    "    thalamus_r = r_av.merge([r_av, r_va, r_vla, r_vlp, r_vpl, r_pul, r_cm, r_md])\n",
    "\n",
    "    thalamus = thalamus_l.merge(thalamus_r)\n",
    "\n",
    "\n",
    "    thalamus_l_position = [(-94.93243156636869, 20.80048340483919, -3.6609767056495),(0.3974123737947691, 17.327023074415486, -8.203546407573794), (0.04772021646463825, 0.003395016921239654, 0.9988549718556106)]\n",
    "\n",
    "    thalamus_r_position = [(95.60832355891446, 12.133001374531405, -13.531167049111657), (0.3974123737947691, 17.327023074415486, -8.203546407573794), (0.059400106557700456, 0.06727258338579319, 0.9959648723050103)]\n",
    "    thalamus_position = [(11.081681826398091, 14.736747032236908, 123.86774195231541), (-0.04879951477050781, 14.638345837593079, -15.511809825897217), (0.02417376168990972, 0.9997042960265031, -0.0026362382126156984)]\n",
    "\n",
    "\n",
    "    p = pv.Plotter()\n",
    "    p.add_mesh(thalamus)\n",
    "    p.update_scalar_bar_range([vmin, vmax])\n",
    "\n",
    "    p.show(jupyter_backend='static', cpos=thalamus_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5162b414-fe05-47f6-b807-01e08d0e75d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.hstack([np.arange(4, 8), np.arange(0, 4), np.arange(16, 24), np.arange(8, 16)])\n",
    "\n",
    "seg_vol_left = seg_vol_ep[left,:]\n",
    "seg_vol_right = seg_vol_ep[right,:]\n",
    "seg_vol_right_flipped = seg_vol_right[:, ind]\n",
    "seg_vol_ep_ipsi = np.vstack([seg_vol_left, seg_vol_right_flipped])\n",
    "\n",
    "seg_vol_ep_zscore = (seg_vol_ep - np.mean(seg_vol_hc,axis=0))/np.std(seg_vol_hc,axis=0)\n",
    "\n",
    "seg_vol_zscore_left = seg_vol_ep_zscore[left,:]\n",
    "seg_vol_zscore_right = seg_vol_ep_zscore[right,:]\n",
    "\n",
    "seg_vol_zscore_right_flipped = seg_vol_zscore_right[:, ind]\n",
    "\n",
    "seg_vol_ep_ipsi_zscore = np.vstack([seg_vol_zscore_left, seg_vol_zscore_right_flipped])\n",
    "\n",
    "mts_lr = np.hstack([mts[left], mts[right]])\n",
    "nonmts_lr = np.hstack([nonmts[left], nonmts[right]])\n",
    "temporal_lr = np.hstack([temporal[left], temporal[right]])\n",
    "frontal_lr = np.hstack([frontal[left], frontal[right]])\n",
    "left_lr = np.hstack([left[left], left[right]])\n",
    "right_lr = np.hstack([right[left], right[right]])\n",
    "lesional_lr = np.hstack([lesional[left], lesional[right]])\n",
    "nonlesional_lr = np.hstack([nonlesional[left], nonlesional[right]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c39c1151-8d99-44ba-8ac2-fcfc8fb1d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import seaborn as sns\n",
    "from numpy import mean, std # version >= 1.7.1 && <= 1.9.1\n",
    "from math import sqrt\n",
    "\n",
    "def cohen_d(x,y):\n",
    "    return (mean(x) - mean(y)) / sqrt((std(x, ddof=1) ** 2 + std(y, ddof=1) ** 2) / 2.0)\n",
    "\n",
    "def cohen_d_mat(x,y):\n",
    "    return (np.mean(x, axis = 0) - np.mean(y, axis = 0)) / np.sqrt((np.std(x, ddof=1, axis=0) ** 2 + np.std(y, ddof=1, axis=0) ** 2) / 2.0)\n",
    "\n",
    "def z_score(x,y):\n",
    "    return (x-np.mean(y))/np.std(y)\n",
    "\n",
    "ipsi_fmri_lab = [x.replace('L-', 'Ipsi-').replace('R-', 'Contra-') for x in fmri_lab]\n",
    "\n",
    "outfolder = '/Users/smouc/LittLab/Alfredo/Segmentation/Code/figs/'\n",
    "\n",
    "def fig2_rawvolume_plot(g1, g2, title, lab1, lab2):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    ax = plt.subplot()\n",
    "    plt.bar(np.arange(24), np.mean(seg_vol_ep_ipsi[g1,:], axis=0), width = 0.35, yerr = np.std(seg_vol_ep_ipsi[g1,:], axis=0), color = 'b', label = lab1)\n",
    "    plt.bar(np.arange(24)+0.35, np.mean(seg_vol_ep_ipsi[g2,:], axis=0), width = 0.35, yerr = np.std(seg_vol_ep_ipsi[g2,:], axis=0), color = 'r', label = lab2)\n",
    "    ax.set_xticks(np.arange(24))\n",
    "    ax.set_xticklabels(ipsi_fmri_lab, rotation = 75)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.legend(loc='upper right', frameon=False)\n",
    "    # ax.spines['bottom'].set_visible(False)\n",
    "    \n",
    "    pvals_g1g2 = []\n",
    "    pvals_g1ref = []\n",
    "    pvals_g2ref = []\n",
    "    \n",
    "    for i in range(24):\n",
    "        pvals_g1g2.append(stats.ttest_ind(seg_vol_ep_ipsi_zscore[g1,i], seg_vol_ep_ipsi_zscore[g2,i])[1])\n",
    "        #pvals_g1ref.append(stats.ttest_ind(seg_vol_ep_ipsi[g1,i], seg_vol_hc[:,i])[1])\n",
    "        #pvals_g2ref.append(stats.ttest_ind(seg_vol_ep_ipsi[g2,i], seg_vol_hc[:,i])[1])\n",
    "        pvals_g1ref.append(stats.ttest_1samp(seg_vol_ep_ipsi_zscore[g1,i], popmean=0)[1])\n",
    "        pvals_g2ref.append(stats.ttest_1samp(seg_vol_ep_ipsi_zscore[g2,i], popmean=0)[1])\n",
    "    pvals_g1g2bh = multipletests(pvals_g1g2, alpha=0.05, method='fdr_bh')\n",
    "    pvals_g1refbh = multipletests(pvals_g1ref, alpha=0.05, method='fdr_bh')\n",
    "    pvals_g2refbh = multipletests(pvals_g2ref, alpha=0.05, method='fdr_bh')\n",
    "    \n",
    "    print('Group 1')\n",
    "    for i,p in enumerate(pvals_g1refbh[1]):\n",
    "        print(ipsi_fmri_lab[i], ': ', p,'\\n')\n",
    "\n",
    "    print('Group 2')\n",
    "    for i,p in enumerate(pvals_g2refbh[1]):\n",
    "        print(ipsi_fmri_lab[i], ': ', p,'\\n')\n",
    "    \n",
    "    # print(pvals_g1refbh[0])\n",
    "    # print(pvals_g2refbh[0])\n",
    "    \n",
    "    star_left_ind = np.arange(24) - .04\n",
    "    star_right_ind = star_left_ind + .28\n",
    "    \n",
    "    plt.scatter(star_left_ind[pvals_g1refbh[0]], (np.mean(seg_vol_ep_ipsi[g1,:], axis=0) + np.std(seg_vol_ep_ipsi[g1,:], axis=0) + 200)[pvals_g1refbh[0]], color = 'k', marker = \"*\")\n",
    "    plt.scatter(star_right_ind[pvals_g2refbh[0]], (np.mean(seg_vol_ep_ipsi[g2,:], axis=0) + np.std(seg_vol_ep_ipsi[g2,:], axis=0) + 200)[pvals_g2refbh[0]], color = 'k', marker = \"*\")\n",
    "    plt.ylim([0, 5000])\n",
    "    \n",
    "    #plt.savefig(outfolder + 'ttestvolume_figure_%s.svg'%title, format='svg', bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    return cohen_d_mat(seg_vol_ep_ipsi_zscore[g1,:], seg_vol_ep_ipsi_zscore[g2,:])\n",
    "\n",
    "\n",
    "def fig2_cohensd_plot(g1, g2, title, lab1, lab2):\n",
    "    plt.figure(figsize=(14,5))\n",
    "    cohend_g1 = []\n",
    "    cohend_g2 = []\n",
    "    for i in range(24):\n",
    "        cohend_g1.append(cohen_d_mat(seg_vol_ep_ipsi[g1,i], seg_vol_hc[:,i]))\n",
    "        cohend_g2.append(cohen_d_mat(seg_vol_ep_ipsi[g2,i], seg_vol_hc[:,i]))\n",
    "    \n",
    "    df_plot = pd.DataFrame()\n",
    "    df_plot[\"Cohen's d\"] = cohend_g1 + cohend_g2\n",
    "    df_plot[\"Group\"] = [lab1]*24 + [lab2]*24\n",
    "    df_plot[\"Region\"] = ipsi_fmri_lab*2\n",
    "    sns.barplot(x='Region', y=\"Cohen's d\", hue='Group', data=df_plot, linewidth=0.5, edgecolor='k', width=0.5)\n",
    "    plt.hlines(y=0, xmin=-0.5, xmax=23.5, color='k')\n",
    "    sns.despine()\n",
    "    plt.xticks(rotation=75)\n",
    "    # pyvista plot for g1\n",
    "    plot_ashs_no_tail(cohend_g1[:8],vmin=-4,vmax=4)\n",
    "    plot_thomas(cohend_g1[8:],vmin=-2,vmax=2)\n",
    "\n",
    "    # pyvista plot for g2\n",
    "    plot_ashs_no_tail(cohend_g2[:8],vmin=-4,vmax=4)\n",
    "    plot_thomas(cohend_g2[8:],vmin=-2,vmax=2)\n",
    "\n",
    "def fig2_zscore_plot(g1, g2, title, lab1, lab2):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    df_plot_all = pd.DataFrame()\n",
    "    seg_g1 = seg_vol_ep_ipsi_zscore[g1,:]\n",
    "    for i in range(seg_g1.shape[0]):\n",
    "        zscore_g1 = []\n",
    "        for j in range(24):\n",
    "            zscore_g1.append(seg_g1[i,j])\n",
    "        \n",
    "        df_plot = pd.DataFrame()\n",
    "        df_plot[\"Z-Score\"] = zscore_g1\n",
    "        df_plot[\"Group\"] = [lab1]*24\n",
    "        df_plot[\"Region\"] = ipsi_fmri_lab\n",
    "\n",
    "        df_plot_all = pd.concat((df_plot_all, df_plot))\n",
    "\n",
    "    seg_g2 = seg_vol_ep_ipsi_zscore[g2,:]\n",
    "    for i in range(seg_g2.shape[0]):\n",
    "        zscore_g2 = []\n",
    "        for j in range(24):\n",
    "            zscore_g2.append(seg_g2[i,j])\n",
    "        \n",
    "        df_plot = pd.DataFrame()\n",
    "        df_plot[\"Z-Score\"] = zscore_g2\n",
    "        df_plot[\"Group\"] = [lab2]*24\n",
    "        df_plot[\"Region\"] = ipsi_fmri_lab\n",
    "\n",
    "        df_plot_all = pd.concat((df_plot_all, df_plot))\n",
    "\n",
    "\n",
    "    sns.barplot(x='Region', y=\"Z-Score\", hue='Group', data=df_plot_all, linewidth=0.5, edgecolor='k')\n",
    "    sns.despine()\n",
    "    plt.hlines(y=0, xmin=-0.5, xmax=23.5, color='k')\n",
    "    plt.xticks(rotation=75)\n",
    "\n",
    "def fig2_rawvolume2_plot(g1, g2, title, lab1, lab2):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    df_plot_all = pd.DataFrame()\n",
    "    seg_g1 = seg_vol_ep_ipsi[g1,:]\n",
    "    for i in range(seg_g1.shape[0]):\n",
    "        zscore_g1 = []\n",
    "        for j in range(24):\n",
    "            zscore_g1.append(seg_g1[i,j])\n",
    "        \n",
    "        df_plot = pd.DataFrame()\n",
    "        df_plot[\"Volume\"] = zscore_g1\n",
    "        df_plot[\"Group\"] = [lab1]*24\n",
    "        df_plot[\"Region\"] = ipsi_fmri_lab\n",
    "\n",
    "        df_plot_all = pd.concat((df_plot_all, df_plot))\n",
    "\n",
    "    seg_g2 = seg_vol_ep_ipsi[g2,:]\n",
    "    for i in range(seg_g2.shape[0]):\n",
    "        zscore_g2 = []\n",
    "        for j in range(24):\n",
    "            zscore_g2.append(seg_g2[i,j])\n",
    "        \n",
    "        df_plot = pd.DataFrame()\n",
    "        df_plot[\"Volume\"] = zscore_g2\n",
    "        df_plot[\"Group\"] = [lab2]*24\n",
    "        df_plot[\"Region\"] = ipsi_fmri_lab\n",
    "\n",
    "        df_plot_all = pd.concat((df_plot_all, df_plot))\n",
    "\n",
    "\n",
    "    seg_g3 = seg_vol_hc\n",
    "    for i in range(seg_g3.shape[0]):\n",
    "        zscore_g3 = []\n",
    "        for j in range(24):\n",
    "            zscore_g3.append(seg_g3[i,j])\n",
    "        \n",
    "        df_plot = pd.DataFrame()\n",
    "        df_plot[\"Volume\"] = zscore_g3\n",
    "        df_plot[\"Group\"] = ['Control']*24\n",
    "        df_plot[\"Region\"] = ipsi_fmri_lab\n",
    "\n",
    "        df_plot_all = pd.concat((df_plot_all, df_plot))\n",
    "\n",
    "    sns.barplot(x='Region', y=\"Volume\", hue='Group', data=df_plot_all, linewidth=0.5, edgecolor='k')\n",
    "    sns.despine()\n",
    "    plt.hlines(y=0, xmin=-0.5, xmax=23.5, color='k')\n",
    "    plt.xticks(rotation=75)\n",
    "\n",
    "\n",
    "def fig2_zscore_volume_single_plot(g1,  title, lab1):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    df_plot_all = pd.DataFrame()\n",
    "    seg_g1 = seg_vol_ep_ipsi_zscore[g1,:]\n",
    "    for i in range(seg_g1.shape[0]):\n",
    "        zscore_g1 = []\n",
    "        for j in range(24):\n",
    "            zscore_g1.append(seg_g1[i,j])\n",
    "        \n",
    "        df_plot = pd.DataFrame()\n",
    "        df_plot[\"Volume\"] = zscore_g1\n",
    "        df_plot[\"Group\"] = [lab1]*24\n",
    "        df_plot[\"Region\"] = ipsi_fmri_lab\n",
    "        df_plot[\"Structure\"] = ['ipsi-Hippocampus']*4 + ['contra-Hippocampus']*4 + ['ipsi-Thalamus']*8 + ['contra-Thalamus']*8\n",
    "        df_plot_all = pd.concat((df_plot_all, df_plot))\n",
    "\n",
    "\n",
    "    sns.barplot(x='Region', y=\"Volume\", hue='Structure', data=df_plot_all, linewidth=1, edgecolor='k', dodge=False)\n",
    "    sns.despine()\n",
    "    plt.hlines(y=0, xmin=-0.5, xmax=23.5, color='k')\n",
    "    plt.xticks(rotation=75)\n",
    "    plt.xlabel('Region',fontweight='bold')\n",
    "    plt.ylabel('Volume',fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('/Volumes/T7_Shield/research/CNT/P36_hippo_thal_7t/outputs/figures/paper_figures/jupyter_figures/'+lab1+'_raw_volumes.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197b5366-3acb-4cf1-a7b2-c1c4153c055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette('Spectral')\n",
    "print('MTS vs nonMTS')\n",
    "cohend_mts_nonmts = fig2_rawvolume2_plot(mts_lr, nonmts_lr, 'mts', 'MTS', 'No MTS')\n",
    "fig2_cohensd_plot(mts_lr, nonmts_lr, 'mts', 'MTS', 'No MTS')\n",
    "fig2_zscore_plot(mts_lr, nonmts_lr, 'mts', 'MTS', 'No MTS')\n",
    "\n",
    "print('Left Temporal vs Right Temporal')\n",
    "cohend_ltle_rtle = fig2_rawvolume2_plot(left_lr * temporal_lr, right_lr * temporal_lr, 'ltle', 'LTLE', 'RTLE')\n",
    "fig2_cohensd_plot(left_lr * temporal_lr, right_lr * temporal_lr, 'ltle', 'LTLE', 'RTLE')\n",
    "fig2_zscore_plot(left_lr * temporal_lr, right_lr * temporal_lr, 'ltle', 'LTLE', 'RTLE')\n",
    "\n",
    "print('Temporal vs Frontal')\n",
    "cohend_temp_frontal = fig2_rawvolume2_plot(temporal_lr, frontal_lr, 'temp', 'Temporal', 'Frontal')\n",
    "fig2_cohensd_plot(temporal_lr, frontal_lr, 'temp', 'Temporal', 'Frontal')\n",
    "fig2_zscore_plot(temporal_lr, frontal_lr, 'temp', 'Temporal', 'Frontal')\n",
    "\n",
    "print('Lesional vs non lesional')\n",
    "cohend_les_nonles = fig2_rawvolume2_plot(lesional_lr, nonlesional_lr, 'les', 'Lesional', 'Nonlesional')\n",
    "fig2_cohensd_plot(lesional_lr, nonlesional_lr, 'les', 'Lesional', 'Nonlesional')\n",
    "fig2_zscore_plot(lesional_lr, nonlesional_lr, 'les', 'Lesional', 'Nonlesional')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4610ca-8ae9-45fe-95e9-90ff89125553",
   "metadata": {},
   "source": [
    "## Figure 3 - Hippocampal and Thalamic Atrophy Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c953b34-7403-4b93-93db-d597a169e205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 24)\n",
      "(33, 4)\n"
     ]
    }
   ],
   "source": [
    "with open(r'lda_components.pickle', 'rb') as f:\n",
    "    # left hippocampus first column, right hippocampus second column\n",
    "    file = pickle.load(f)\n",
    "    lda_comp = file['lda_components']\n",
    "    lda_mod = file['lda_model']\n",
    "\n",
    "print(lda_comp.shape)\n",
    "\n",
    "seg_vol_ep = seg_vol[[pt_info[pt_info['Subject']==x]['Final_Loc'].values[0] != 'Control' for x in vol_pts], :]\n",
    "seg_vol_hc = seg_vol[[pt_info[pt_info['Subject']==x]['Final_Loc'].values[0] == 'Control' for x in vol_pts], :]\n",
    "\n",
    "seg_vol_ep_norm = np.abs((seg_vol_ep - np.mean(seg_vol_hc,axis=0))/np.std(seg_vol_hc,axis=0)*10).astype(int)\n",
    "\n",
    "seg_vol_norm_left = seg_vol_ep_norm[left,:]\n",
    "seg_vol_norm_right = seg_vol_ep_norm[right,:]\n",
    "\n",
    "ind = np.hstack([np.arange(4, 8), np.arange(0, 4), np.arange(16, 24), np.arange(8, 16)])\n",
    "seg_vol_norm_right_flipped = seg_vol_norm_right[:, ind]\n",
    "\n",
    "ep_seg_vol_norm = np.vstack([seg_vol_norm_left, seg_vol_norm_right_flipped])\n",
    "ep_seg_vol_factors = lda_mod.transform(ep_seg_vol_norm)\n",
    "ep_seg_vol_norm_lr = np.vstack([seg_vol_norm_left, seg_vol_norm_right])\n",
    "ep_seg_vol_factors_lr = lda_mod.transform(ep_seg_vol_norm_lr)\n",
    "\n",
    "print(ep_seg_vol_factors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b96ae-18c5-4ef5-87a8-b8994aafd045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the LDA components\n",
    "lda = lda_mod\n",
    "for i in range(4):\n",
    "    component = i\n",
    "    print('Factor ', i+1)\n",
    "    lda_components = lda.components_/ lda.components_.sum(axis=1)[:, np.newaxis]\n",
    "    plot_ashs_no_tail(lda_components[component,:8], 0, 0.07)\n",
    "    plot_thomas(lda_components[component,8:], 0, 0.07)\n",
    "    # plt.bar(x=np.arange(len(ashs_regions_to_gather)+len(thomas_regions_to_gather)),height=lda_components[component,:])\n",
    "    # plt.xticks(np.arange(len(ashs_regions_to_gather)+len(thomas_regions_to_gather)), ashs_regions_to_gather+thomas_regions_to_gather, rotation=90)\n",
    "\n",
    "    df_plot = pd.DataFrame()\n",
    "    df_plot['Component Weight'] = lda_components[component,:]\n",
    "    df_plot['Component Name'] =  ipsi_fmri_lab\n",
    "\n",
    "    df_plot['Region'] = ['I-Hippocampus']*4 + ['C-Hippocampus']*4 + ['I-Thalamus']*8 + ['C-Thalamus']*8\n",
    "\n",
    "    sns.set_palette(['#9D291E', '#FB8B24','#1E929D','#143747'])\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(121)\n",
    "    sns.barplot(data=df_plot, x='Component Name', y='Component Weight', hue='Region' ,order=df_plot['Component Name'].values[np.argsort(lda_components[component,:])[::-1]],\n",
    "                edgecolor='k', dodge=False, saturation=1)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.subplot(122)\n",
    "    sns.barplot(data=df_plot, x='Region', y='Component Weight', edgecolor='k', linewidth=3, capsize=.4, errcolor=\"0\", saturation=1)\n",
    "    plt.xticks(rotation=90)\n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('/Volumes/T7_Shield/research/CNT/P36_hippo_thal_7t/outputs/figures/paper_figures/jupyter_figures/factor'+str(i+1)+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a182bce-5d9e-491a-8841-e60079ae3db2",
   "metadata": {},
   "source": [
    "## Figure 4 - Distribution of disease factors across different epilepsy subtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "028d9398-c03c-4370-9bfa-57400a2ab800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_factor_heatmap(g1,lab):\n",
    "    sorted1 = np.argsort(ep_seg_vol_factors[g1][:,0])\n",
    "    sorted2 = np.argsort(ep_seg_vol_factors[g1][:,1])\n",
    "    sorted3 = np.argsort(ep_seg_vol_factors[g1][:,2])\n",
    "    sorted4 = np.argsort(ep_seg_vol_factors[g1][:,3])\n",
    "    plt.subplot(141)\n",
    "    plt.imshow(ep_seg_vol_factors[g1][sorted1,:], cmap='inferno')\n",
    "    plt.subplot(142)\n",
    "    plt.imshow(ep_seg_vol_factors[g1][sorted2,:], cmap='inferno')\n",
    "    plt.subplot(143)\n",
    "    plt.imshow(ep_seg_vol_factors[g1][sorted3,:], cmap='inferno')\n",
    "    plt.subplot(144)\n",
    "    plt.imshow(ep_seg_vol_factors[g1][sorted4,:], cmap='inferno')\n",
    "    plt.colorbar()\n",
    "    # plt.savefig(os.path.join('/Volumes/T7_Shield/research/CNT/P36_hippo_thal_7t/outputs/figures/paper_figures/jupyter_figures','factor_heatmatp_'+lab+'.pdf'))\n",
    "    plt.figure()\n",
    "\n",
    "    print('Maximum factors: ',np.argmax(ep_seg_vol_factors[g1],axis=1)+1)\n",
    "    spearman_matrix = np.zeros((4,4))\n",
    "    spearman_pvalues = np.zeros((4,4))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            spearman_matrix[i,j] = stats.spearmanr(ep_seg_vol_factors[g1][:,i],ep_seg_vol_factors[g1][:,j])[0]\n",
    "            spearman_pvalues[i,j] = stats.spearmanr(ep_seg_vol_factors[g1][:,i],ep_seg_vol_factors[g1][:,j])[1]\n",
    "\n",
    "    spearman_matrix[np.triu_indices(4,0)] = np.nan\n",
    "    print(spearman_matrix)\n",
    "    print('Significant cells: ',(spearman_pvalues*6))\n",
    "    # Create the heatmap plot\n",
    "    sns.set_style(\"white\")\n",
    "    ax = sns.heatmap(spearman_matrix, cmap='RdBu', vmin=-1, vmax=1, annot=True,\n",
    "                    fmt='.2f', annot_kws={\"size\": 14}, linewidths=.5,\n",
    "                    xticklabels=['Factor 1', 'Factor 2', 'Factor 3'],\n",
    "                    yticklabels=['', 'Factor 2', 'Factor 3', 'Factor 4'])\n",
    "    # plt.savefig(os.path.join('/Volumes/T7_Shield/research/CNT/P36_hippo_thal_7t/outputs/figures/paper_figures/jupyter_figures','factor_cofluctuation_'+lab+'.pdf'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0d3c9e-5474-4ecf-b79b-41e0caa777f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_factor_heatmap(mts_lr,'mts')\n",
    "plt.figure()\n",
    "plot_factor_heatmap(nonmts_lr,'non-mts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b831ae-4de2-44a4-a3ce-ba218a5985c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_factor_heatmap(left_lr*temporal_lr, 'LTLE')\n",
    "plt.figure()\n",
    "plot_factor_heatmap(right_lr*temporal_lr, 'RTLE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f66dfd-fd6c-4372-9dfb-948dd2b35297",
   "metadata": {},
   "source": [
    "5 sense scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cf0d6ef9-a123-46ce-953e-8d029e1739c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fivesense_vals = list(map(lambda x: pt_info[pt_info['Subject']==x]['fivesense'].values[0] if x in list(pt_info.Subject) else np.nan, vol_pts))\n",
    "patient_vals = list(map(lambda x: pt_info[pt_info['Subject']==x]['Subject'].values[0] if x in list(pt_info.Subject) else np.nan, vol_pts))\n",
    "loc_vals = list(map(lambda x: pt_info[pt_info['Subject']==x]['Final_Loc'].values[0] if x in list(pt_info.Subject) else np.nan, vol_pts))\n",
    "outcome_vals = list(map(lambda x: pt_info[pt_info['Subject']==x]['Outcome'].values[0] if x in list(pt_info.Subject) else np.nan, vol_pts))\n",
    "lat_vals = list(map(lambda x: pt_info[pt_info['Subject']==x]['Lat'].values[0] if x in list(pt_info.Subject) else np.nan, vol_pts))\n",
    "mts_vals = list(map(lambda x: pt_info[pt_info['Subject']==x]['MTS (y/n)'].values[0] if x in list(pt_info.Subject) else np.nan, vol_pts))\n",
    "\n",
    "fivesense_vals = np.array(fivesense_vals)[[pt_info[pt_info['Subject']==x]['Final_Loc'].values[0] != 'Control' for x in vol_pts]]\n",
    "fivesense_vals = np.hstack((fivesense_vals[left], fivesense_vals[right]))\n",
    "\n",
    "patient_vals = np.array(patient_vals)[[pt_info[pt_info['Subject']==x]['Final_Loc'].values[0] != 'Control' for x in vol_pts]]\n",
    "patient_vals = np.hstack((patient_vals[left], patient_vals[right]))\n",
    "\n",
    "loc_vals = np.array(loc_vals)[[pt_info[pt_info['Subject']==x]['Final_Loc'].values[0] != 'Control' for x in vol_pts]]\n",
    "loc_vals = np.hstack((loc_vals[left], loc_vals[right]))\n",
    "\n",
    "outcome_vals = np.array(outcome_vals)[[pt_info[pt_info['Subject']==x]['Final_Loc'].values[0] != 'Control' for x in vol_pts]]\n",
    "outcome_vals = np.hstack((outcome_vals[left], outcome_vals[right]))\n",
    "\n",
    "lat_vals = np.array(lat_vals)[[pt_info[pt_info['Subject']==x]['Final_Loc'].values[0] != 'Control' for x in vol_pts]]\n",
    "lat_vals = np.hstack((lat_vals[left], lat_vals[right]))\n",
    "\n",
    "mts_vals = np.array(mts_vals)[[pt_info[pt_info['Subject']==x]['Final_Loc'].values[0] != 'Control' for x in vol_pts]]\n",
    "mts_vals = np.hstack((mts_vals[left], mts_vals[right]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208bd94e-e590-4586-9756-8fb81bbb78f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = pd.DataFrame()\n",
    "df_plot['Fivesense'] =  fivesense_vals\n",
    "df_plot['Subject'] = patient_vals\n",
    "df_plot['Final Location'] = loc_vals\n",
    "df_plot['Good Outcome'] = outcome_vals\n",
    "df_plot['Lat'] = lat_vals\n",
    "df_plot['MTS'] = mts_vals\n",
    "df_plot['Factor 3'] = ep_seg_vol_factors[:,2]\n",
    "df_plot['Factor 1'] = ep_seg_vol_factors[:,0]\n",
    "df_plot['Factor 2'] = ep_seg_vol_factors[:,1]\n",
    "df_plot['Factor 4'] = ep_seg_vol_factors[:,3]\n",
    "df_plot['Factor Sum'] = ep_seg_vol_factors[:,0] + ep_seg_vol_factors[:,1] + ep_seg_vol_factors[:,2]\n",
    "\n",
    "df_plot = df_plot.dropna()\n",
    "\n",
    "sns.lmplot(x='Fivesense', y='Factor 4',  data=df_plot[df_plot['Final Location']=='Temporal'])\n",
    "plt.xlabel('5-sense Score', fontweight='bold')\n",
    "plt.ylabel('Factor 4', fontweight='bold')\n",
    "\n",
    "plt.figure()\n",
    "sns.lmplot(x='Fivesense', y='Factor 3',  data=df_plot[df_plot['Final Location']=='Temporal'])\n",
    "plt.xlabel('5-sense Score', fontweight='bold')\n",
    "plt.ylabel('Factor 3', fontweight='bold')\n",
    "\n",
    "plt.figure()\n",
    "sns.lmplot(x='Fivesense', y='Factor 2',  data=df_plot[df_plot['Final Location']=='Temporal'])\n",
    "plt.xlabel('5-sense Score', fontweight='bold')\n",
    "plt.ylabel('Factor 2', fontweight='bold')\n",
    "\n",
    "plt.figure()\n",
    "sns.lmplot(x='Fivesense', y='Factor 1',  data=df_plot[df_plot['Final Location']=='Temporal'])\n",
    "plt.xlabel('5-sense Score', fontweight='bold')\n",
    "plt.ylabel('Factor 1', fontweight='bold')\n",
    "\n",
    "plt.figure()\n",
    "sns.lmplot(x='Fivesense', y='Factor Sum',  data=df_plot[df_plot['Final Location']=='Temporal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aae7a0-afd0-46f9-afb0-33e8a1df6a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Factor 1: ',stats.pearsonr(df_plot['Fivesense'],df_plot['Factor 1']))\n",
    "print('Factor 2: ',stats.pearsonr(df_plot['Fivesense'],df_plot['Factor 2']))\n",
    "print('Factor 3: ',stats.pearsonr(df_plot['Fivesense'],df_plot['Factor 3']))\n",
    "print('Factor 4: ',stats.pearsonr(df_plot['Fivesense'],df_plot['Factor 4']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b19476-3b6c-4e26-b1a1-ddbb58426f7c",
   "metadata": {},
   "source": [
    "## Figure 5 - Hierarchical clustering of atrophy factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43db59-6e88-4489-9d57-9292d544cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, leaves_list\n",
    "\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "row_clusters = linkage(ep_seg_vol_factors, method='ward')\n",
    "\n",
    "# Plot dendrogram to find the optimal number of clusters\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "dendrogram(row_clusters, ax=ax)\n",
    "ax.set_title('Dendrogram')\n",
    "#plt.savefig('dendrogram.pdf')\n",
    "plt.show()\n",
    "\n",
    "# Reorder data based on clustering\n",
    "rows_order = leaves_list(row_clusters)\n",
    "sorted_data = ep_seg_vol_factors[rows_order, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76556c5f-7441-47ec-ab14-a84a1b20bf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sorted data\n",
    "fig, ax = plt.subplots(figsize=(4, 8))\n",
    "cax = ax.imshow(sorted_data, aspect='auto', cmap='inferno')\n",
    "fig.colorbar(cax)\n",
    "ax.set_title('Sorted Data')\n",
    "plt.yticks(np.arange(len(rows_order)), rows_order)\n",
    "plt.xticks([0,1,2,3],[1,2,3,4])\n",
    "plt.xlabel('Factor Number')\n",
    "#plt.savefig('sorted_factor_data_dendrogram.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
